{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b6b077",
   "metadata": {},
   "source": [
    "# Training a Classification model on the extracted features\n",
    "\n",
    "Instead of using the full dataset, we just consider $10\\%$, totaling 2500 images. We consider the Logistic Regression model to perform the classification. Transfer learning some time does not require much data, here is an example, we obtain $0.9856$ as accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae174d87",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8914445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import dogs_vs_cats_config as config\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import h5py\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef99375",
   "metadata": {},
   "source": [
    "## Importing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117d8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = h5py.File(config.FEATURES, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581b9bd",
   "metadata": {},
   "source": [
    "## Traning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eda6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "1875\n"
     ]
    }
   ],
   "source": [
    "i = int(features[\"labels\"].shape[0] * 0.1)\n",
    "print(i)\n",
    "ii = int(i*0.75)\n",
    "print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f40a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters\n",
    "params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0], \"solver\" : [\"newton-cg\", \"lbfgs\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa46f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(LogisticRegression(max_iter=1000), params, cv = 5, n_jobs=1) # with cross validation equal to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99763051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=1,\n",
       "             param_grid={'C': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
       "                         'solver': ['newton-cg', 'lbfgs']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(features[\"features\"][:ii], features[\"labels\"][:ii]) # [:i] we consider the training the staring from the index 0 into i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46c76eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 0.1, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters {}\".format(model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b2bd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(features[\"features\"][ii:i]) #[i:] we consider the test set starting from i until the last index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b4149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['cats', 'dogs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b858b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(features[\"labels\"][ii:i], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb2d55b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       319\n",
      "           1       0.99      0.98      0.99       306\n",
      "\n",
      "    accuracy                           0.99       625\n",
      "   macro avg       0.99      0.99      0.99       625\n",
      "weighted avg       0.99      0.99      0.99       625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70d94bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] score: 0.9856\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(features[\"labels\"][ii:i], predictions)\n",
    "print(\"[INFO] score: {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
