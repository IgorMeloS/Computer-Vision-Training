{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b313a126",
   "metadata": {},
   "source": [
    "# Extracting Features using pre-trained models and classification\n",
    "\n",
    "In this example we explore the concept of feature extraction using a pre-trained model on the Animals dataset. To store the features we consider the HDF5 file format, using the module HDF5DatasetWriter. We consider the VGG16 trained on Image Net dataset. After the features extraction, we deploy the image classification, using a Machine Learning model of classification, Logistic Regression. \n",
    "\n",
    "The Animals dataset is composed by three classes and 1000 images of each classes: Cats, Dogs and Pandas.\n",
    "\n",
    "The feature extraction is made on the convolutional part of the VGG16 network, we won't consider the fully connected layer (the fine tuning consider all the network)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f899a6",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb54524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#compvis module\n",
    "from compvis.io import HDF5DatasetWriter\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29483d05",
   "metadata": {},
   "source": [
    "## Setting the dateset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f4e74",
   "metadata": {},
   "source": [
    "**Defining the paths for the dataset and the HDF5 file with the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d421d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/igor/Documents/Artificial_Inteligence/Datasets/Animals\"\n",
    "HDF5_PATH = \"/home/igor/Documents/Artificial_Inteligence/Datasets/Animals/hdf5/features.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81607e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesPath = list(paths.list_images(DATA_PATH)) # making a list with all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df8655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(imagesPath) # shuffling the images to have a better memory access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfe00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32 # defining the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf6c93",
   "metadata": {},
   "source": [
    "**Creating the list of labels**\n",
    "\n",
    "We split the string that contains the path, for example, Data/Animals/Class/Photo. We grab the class applying p.split(os.path.sep)[-2]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8ce067",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [p.split(os.path.sep)[-2] for p in imagesPath]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c84016",
   "metadata": {},
   "source": [
    "**Encoding the labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "858e968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f9e6d",
   "metadata": {},
   "source": [
    "## Defining the model for the feature extraction\n",
    "\n",
    "The arguments for the VGG16 are weights and include_top. The first is \"imagenet\" and the second is False, we don't want to consider the fully connected layers, the classification will be made after by own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37871563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights = \"imagenet\", include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae98e1",
   "metadata": {},
   "source": [
    "**Building the dataset writer**\n",
    "\n",
    "To build the dataset to store the features, we consider the class HDF5DatasetWriter. This class accepets 4 arguments dims (tuple with the number of raw and columns, in our case the number of images and the feature vector size, $7x7x512$), outputPath (the path to the hdf5 file), datakey (the name of the file), bufsize (buffer size by default 1000). The VGG16 at the end of the convolution layer returns 512 filters with size of $(7x7)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "772c9791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The supplied 'outputPath' already exist \n",
      "Do you want overwrite (be sure)? Enter yes or no: yes\n"
     ]
    }
   ],
   "source": [
    "dataset = HDF5DatasetWriter((len(imagesPath), 512*7*7), HDF5_PATH, \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0606efb",
   "metadata": {},
   "source": [
    "**Creating the list with the classes**, this function returns a list with names classes in the string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1931bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.storeClassLabels(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ed490",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c3dd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100% |#####################################| Time: 0:00:31\n"
     ]
    }
   ],
   "source": [
    "# Defining a progress bar\n",
    "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \",\n",
    "           progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagesPath), widgets=widgets).start()\n",
    "# main loop over all images with a step size corresponding with the batch size\n",
    "for i in np.arange(0, len(imagesPath), bs):\n",
    "    \n",
    "    batchPaths = imagesPath[i : i + bs] # list with the image pahts in the batch\n",
    "    batchLabels = labels[i : i + bs]  # list with the labels in the batch\n",
    "    batchImages = [] # empty list to store the image to the feature extraction\n",
    "    \n",
    "    #secondary loop to read and store the images in the batch size\n",
    "    for (j, imgPath) in enumerate(batchPaths):\n",
    "        image = load_img(imgPath, target_size=(224,224)) # reading and resizing the images\n",
    "        image = img_to_array(image) # converting the image into an array\n",
    "        image = np.expand_dims(image, axis=0) # expanding the dimensions to respect the channels\n",
    "        image = imagenet_utils.preprocess_input(image) # preprocssing the image\n",
    "        batchImages.append(image) # adding the current image into the image list\n",
    "        \n",
    "    batchImages = np.vstack(batchImages) # stacking the imgs\n",
    "    features = model.predict(batchImages, batch_size=bs) # extracting the features in the batch\n",
    "    features = features.reshape((features.shape[0], 512*7*7)) # resizing according with the hdf5 dataset5\n",
    "    dataset.add(features, batchLabels) # adding the features and labels into the dataset\n",
    "    pbar.update(i)\n",
    "dataset.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfd784",
   "metadata": {},
   "source": [
    "# Training the model with the features\n",
    "\n",
    "For this example, we consider the Logistic Regression classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e70aa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4a051",
   "metadata": {},
   "source": [
    "## Loading the HDF5 file with the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8b03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbt = h5py.File(HDF5_PATH, \"r\") # HDF5_PATH the file, r the read mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f903ef",
   "metadata": {},
   "source": [
    "**Defining the size of the training set**\n",
    "\n",
    "As we have 3000 images, we consider $75\\%$ of all images for the training set, totaling 2250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342105f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(dbt[\"labels\"].shape[0]*0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902452ca",
   "metadata": {},
   "source": [
    "## Defining the classification model\n",
    "\n",
    "We consider the Logistic Regression model using GridSearchCV that returns the best model, according with the hyperparemeters.\n",
    "\n",
    "The hyperparemeters used in this example are $C$ the strictness and the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f4728e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters\n",
    "params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0], \"solver\" : [\"newton-cg\", \"lbfgs\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50278fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "model = GridSearchCV(LogisticRegression(), params, cv = 5, n_jobs=1) # with cross validation equal to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b69a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=1,\n",
       "             param_grid={'C': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
       "                         'solver': ['newton-cg', 'lbfgs']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(dbt[\"features\"][:i], dbt[\"labels\"][:i]) # [:i] we consider the training the staring from the index 0 into i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51daf1",
   "metadata": {},
   "source": [
    "**The best parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "637c5c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 1000.0, 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters {}\".format(model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91991c",
   "metadata": {},
   "source": [
    "**Predicting on the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37eba85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dbt[\"features\"][i:]) #[i:] we consider the test set starting from i until the last index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f2ef5",
   "metadata": {},
   "source": [
    "**Evaluating the model with the classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3254d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['cats', 'dogs', 'pandas'] # creating the target list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f48f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(dbt[\"labels\"][i:], predictions, target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2499c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.98      1.00      0.99       269\n",
      "        dogs       1.00      0.98      0.99       244\n",
      "      pandas       1.00      1.00      1.00       237\n",
      "\n",
      "    accuracy                           0.99       750\n",
      "   macro avg       0.99      0.99      0.99       750\n",
      "weighted avg       0.99      0.99      0.99       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab0c58",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "As we can see, our model reached excellent results with the feature extraction. The accuracy on the test set is $99\\%$, the best obtained result until now. In the previous examples for the Animals dataset, our best result was $74\\%$ using data augmentation. \n",
    "\n",
    "Transfer Learning can be a good solution when we don't have enough data. Using the VGG16 model trained on ImageNet, we've obtained accurate results. Evidently this animals are included in the ImageNet, due to this fact, we have a good extraction. Consequently, the result of the classification is accurate, the classes are well discriminated among them.\n",
    "\n",
    "For personals projects, situation that sometime we don't enough data, transfer learning is a thing to think about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
