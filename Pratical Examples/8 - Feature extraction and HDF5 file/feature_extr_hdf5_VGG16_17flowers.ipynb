{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b313a126",
   "metadata": {},
   "source": [
    "# Extracting Features using pre-trained models and classification\n",
    "\n",
    "Continuing the exploration about the concept of feature extraction, in this example we consider the 17 Flowers dataset. The method is the same that the previous example, we consider the VGG16 on the ImageNet, we store the features in the hdf5 file, finally, we train the classification model.\n",
    "\n",
    "This is the first time we explore the 17 Flowers dataset, as the name suggests, we have 17 classes of flowers containing 80 images. The dataset is interesting because there is 17 class and not enough images. We are going to see the power of the transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f899a6",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb54524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#compvis module\n",
    "from compvis.io import HDF5DatasetWriter\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import progressbar\n",
    "import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29483d05",
   "metadata": {},
   "source": [
    "## Setting the dateset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f4e74",
   "metadata": {},
   "source": [
    "**Defining the paths for the dataset and the HDF5 file with the features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d421d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/igor/Documents/Artificial_Inteligence/Datasets/17flowers\"\n",
    "HDF5_PATH = \"/home/igor/Documents/Artificial_Inteligence/Datasets/17flowers/hdf5/features.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81607e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesPath = list(paths.list_images(DATA_PATH)) # making a list with all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3df8655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(imagesPath) # shuffling the images to have a better memory access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfe00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32 # defining the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf6c93",
   "metadata": {},
   "source": [
    "**Creating the list of labels**\n",
    "\n",
    "We split the string that contains the path, for example, Data/17flowers/Class/Photo. We grab the class applying p.split(os.path.sep)[-2]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8ce067",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [p.split(os.path.sep)[-2] for p in imagesPath]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c84016",
   "metadata": {},
   "source": [
    "**Encoding the labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "858e968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f9e6d",
   "metadata": {},
   "source": [
    "## Defining the model for the feature extraction\n",
    "\n",
    "The arguments for the VGG16 are weights and include_top. The first is \"imagenet\" and the second is False, we don't want to consider the fully connected layers, the classification will be made after by own model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37871563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(weights = \"imagenet\", include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae98e1",
   "metadata": {},
   "source": [
    "**Building the dataset writer**\n",
    "\n",
    "To build the dataset to store the features, we consider the class HDF5DatasetWriter. This class accepets 4 arguments dims (tuple with the number of raw and columns, in our case the number of images and the feature vector size, $7x7x512$), outputPath (the path to the hdf5 file), datakey (the name of the file), bufsize (buffer size by default 1000). The VGG16 at the end of the convolution layer returns 512 filters with size of $(7x7)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "772c9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HDF5DatasetWriter((len(imagesPath), 512*7*7), HDF5_PATH, \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0606efb",
   "metadata": {},
   "source": [
    "**Creating the list with the classes**, this function returns a list with names classes in the string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1931bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.storeClassLabels(le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ed490",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92c3dd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100% |#####################################| Time: 0:00:16\n"
     ]
    }
   ],
   "source": [
    "# Defining a progress bar\n",
    "widgets = [\"Extracting Features: \", progressbar.Percentage(), \" \",\n",
    "           progressbar.Bar(), \" \", progressbar.ETA()]\n",
    "pbar = progressbar.ProgressBar(maxval=len(imagesPath), widgets=widgets).start()\n",
    "# main loop over all images with a step size corresponding with the batch size\n",
    "for i in np.arange(0, len(imagesPath), bs):\n",
    "    \n",
    "    batchPaths = imagesPath[i : i + bs] # list with the image pahts in the batch\n",
    "    batchLabels = labels[i : i + bs]  # list with the labels in the batch\n",
    "    batchImages = [] # empty list to store the image to the feature extraction\n",
    "    \n",
    "    #secondary loop to read and store the images in the batch size\n",
    "    for (j, imgPath) in enumerate(batchPaths):\n",
    "        image = load_img(imgPath, target_size=(224,224)) # reading and resizing the images\n",
    "        image = img_to_array(image) # converting the image into an array\n",
    "        image = np.expand_dims(image, axis=0) # expanding the dimensions to respect the channels\n",
    "        image = imagenet_utils.preprocess_input(image) # preprocssing the image\n",
    "        batchImages.append(image) # adding the current image into the image list\n",
    "        \n",
    "    batchImages = np.vstack(batchImages) # stacking the imgs\n",
    "    features = model.predict(batchImages, batch_size=bs) # extracting the features in the batch\n",
    "    features = features.reshape((features.shape[0], 512*7*7)) # resizing according with the hdf5 dataset5\n",
    "    dataset.add(features, batchLabels) # adding the features and labels into the dataset\n",
    "    pbar.update(i)\n",
    "dataset.close()\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfd784",
   "metadata": {},
   "source": [
    "# Training the model with the features\n",
    "\n",
    "For this example, we consider the Logistic Regression classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e70aa764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import argparse\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4a051",
   "metadata": {},
   "source": [
    "## Loading the HDF5 file with the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8b03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbt = h5py.File(HDF5_PATH, \"r\") # HDF5_PATH the file, r the read mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f903ef",
   "metadata": {},
   "source": [
    "**Defining the size of the training set**\n",
    "\n",
    "As we have 3000 images, we consider $75\\%$ of all images for the training set, totaling 2250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342105f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(dbt[\"labels\"].shape[0]*0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902452ca",
   "metadata": {},
   "source": [
    "## Defining the classification model\n",
    "\n",
    "We consider the Logistic Regression model using GridSearchCV that returns the best model, according with the hyperparemeters.\n",
    "\n",
    "The hyperparemeters used in this example are $C$ the strictness and the solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f4728e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters\n",
    "params = {\"C\": [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0], \"solver\" : [\"newton-cg\", \"lbfgs\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50278fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "model = GridSearchCV(LogisticRegression(max_iter=1000), params, cv = 5, n_jobs=1) # with cross validation equal to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b69a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=1,\n",
       "             param_grid={'C': [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
       "                         'solver': ['newton-cg', 'lbfgs']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(dbt[\"features\"][:i], dbt[\"labels\"][:i]) # [:i] we consider the training the staring from the index 0 into i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51daf1",
   "metadata": {},
   "source": [
    "**The best parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "637c5c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'C': 1.0, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters {}\".format(model.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91991c",
   "metadata": {},
   "source": [
    "**Predicting on the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37eba85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dbt[\"features\"][i:]) #[i:] we consider the test set starting from i until the last index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f2ef5",
   "metadata": {},
   "source": [
    "**Evaluating the model with the classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3254d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['cats', 'dogs', 'pandas'] # creating the target list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f48f487",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(dbt[\"labels\"][i:], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2499c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.50      0.65        22\n",
      "           1       0.91      0.91      0.91        22\n",
      "           2       0.94      0.94      0.94        16\n",
      "           3       1.00      0.88      0.93        16\n",
      "           4       1.00      0.90      0.95        21\n",
      "           5       0.60      0.68      0.64        22\n",
      "           6       0.56      0.95      0.71        19\n",
      "           7       0.96      1.00      0.98        24\n",
      "           8       1.00      0.83      0.90        23\n",
      "           9       0.92      1.00      0.96        22\n",
      "          10       0.86      1.00      0.93        19\n",
      "          11       1.00      1.00      1.00        14\n",
      "          12       1.00      0.89      0.94        19\n",
      "          13       1.00      1.00      1.00        26\n",
      "          14       0.91      0.88      0.89        24\n",
      "          15       1.00      0.94      0.97        17\n",
      "          16       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           0.89       340\n",
      "   macro avg       0.92      0.90      0.90       340\n",
      "weighted avg       0.91      0.89      0.90       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab0c58",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "As is the first time that this dataset is used in this project, we do not have As is the first time that this dataset is used in this project, we do not have a point of comparison. The fact is, the result of the accuracy on the test set is considerable, $91\\%$. Again, transfer learning enabled us to obtain a good classification model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
